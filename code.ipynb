{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('breast_cancer_data.csv')\n",
    "df['diagnosis_dummy'] = (df['diagnosis'] == 'M').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:              diagnosis   No. Observations:                  569\n",
      "Model:                            GLM   Df Residuals:                      567\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -165.01\n",
      "Date:                Thu, 11 Apr 2024   Deviance:                       330.01\n",
      "Time:                        17:46:57   Pearson chi2:                     489.\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):             0.5232\n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "intercept     -15.2459      1.325    -11.509      0.000     -17.842     -12.649\n",
      "radius_mean     1.0336      0.093     11.100      0.000       0.851       1.216\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Assuming 'data' is your DataFrame, 'y_col' is the name of your target variable,\n",
    "# and 'x_cols' are your predictor variables.\n",
    "# data = pd.read_csv('path_to_your_data.csv')  # Load your data\n",
    "y_col = 'diagnosis'\n",
    "x_cols = ['radius_mean']\n",
    "\n",
    "# Add an intercept term to your model\n",
    "df['intercept'] = 1\n",
    "x_cols = ['intercept'] + x_cols\n",
    "\n",
    "X = df[x_cols]\n",
    "y = df[y_col]\n",
    "\n",
    "# Create a GLM model\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "\n",
    "# Fit the model\n",
    "result = model.fit()\n",
    "\n",
    "# Print the fitted parameters\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization successful.\n",
      "[-15.24586346   1.0335883 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def logistic_regression_wls(data, y_col, x_cols):\n",
    "    # Add intercept term to the dataset\n",
    "    data['intercept'] = 1\n",
    "    x_cols = ['intercept'] + x_cols\n",
    "    \n",
    "    X = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    \n",
    "    # Initial guess for the parameters\n",
    "    beta_init = np.zeros(X.shape[1])\n",
    "    \n",
    "    # Logit link function\n",
    "    def logit(p):\n",
    "        return np.log(p / (1 - p))\n",
    "    \n",
    "    # Inverse of the logit function\n",
    "    def logit_inv(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    # The likelihood function for the binomial distribution\n",
    "    def binomial_log_likelihood(beta):\n",
    "        linear_prediction = np.dot(X, beta)\n",
    "        p = logit_inv(linear_prediction)\n",
    "        return -np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "    \n",
    "    # Minimize the negative log likelihood\n",
    "    result = minimize(binomial_log_likelihood, beta_init, method='BFGS')\n",
    "    \n",
    "    if result.success:\n",
    "        fitted_params = result.x\n",
    "        print(\"Optimization successful.\")\n",
    "    else:\n",
    "        raise ValueError(\"Optimization failed.\")\n",
    "    \n",
    "    return fitted_params\n",
    "\n",
    "y_col = 'diagnosis'\n",
    "x_cols = ['radius_mean']\n",
    "\n",
    "params = logistic_regression_wls(df, y_col, x_cols)\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "0    455\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split(df, test_size=0.2, random_state=42)[0]['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "0    569\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization successful.\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'df' is your DataFrame and you've already encoded the 'diagnosis' column as suggested\n",
    "df['diagnosis'] = (df['diagnosis'] == 'M').astype(int)\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "def logistic_regression_wls(data, y_col, x_cols):\n",
    "    data['intercept'] = 1\n",
    "    x_cols = ['intercept'] + x_cols\n",
    "    \n",
    "    X = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    \n",
    "    beta_init = np.zeros(X.shape[1])\n",
    "    \n",
    "    def logit_inv(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def binomial_log_likelihood(beta):\n",
    "        linear_prediction = np.dot(X, beta)\n",
    "        p = logit_inv(linear_prediction)\n",
    "        return -np.sum(y * np.log(p) + (1 - y) * np.log(1 - p))\n",
    "    \n",
    "    result = minimize(binomial_log_likelihood, beta_init, method='BFGS')\n",
    "    \n",
    "    if result.success:\n",
    "        fitted_params = result.x\n",
    "        print(\"Optimization successful.\")\n",
    "    else:\n",
    "        raise ValueError(\"Optimization failed.\")\n",
    "    \n",
    "    return fitted_params\n",
    "\n",
    "# Train the model\n",
    "y_col = 'diagnosis'\n",
    "x_cols = ['radius_mean']\n",
    "params = logistic_regression_wls(df_train, y_col, x_cols)\n",
    "\n",
    "# Predict on test set\n",
    "def predict(data, params):\n",
    "    data['intercept'] = 1\n",
    "    x_cols = ['intercept', 'radius_mean']\n",
    "    X = data[x_cols].values\n",
    "    linear_prediction = np.dot(X, params)\n",
    "    pred_prob = 1 / (1 + np.exp(-linear_prediction))\n",
    "    return pred_prob\n",
    "\n",
    "df_test['pred_prob'] = predict(df_test, params)\n",
    "\n",
    "# Calculate accuracy\n",
    "df_test['predicted_diagnosis'] = (df_test['pred_prob'] > 0.5).astype(int)\n",
    "accuracy = (df_test['predicted_diagnosis'] == df_test['diagnosis']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 1 0 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1\n",
      " 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1\n",
      " 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0\n",
      " 1 1 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 1 1 0 0 1\n",
      " 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0 0 1\n",
      " 1 1 1 0 1 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 1 1 1 0 0 0]\n",
      "LD [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf]\n",
      "LD2 [inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf inf\n",
      " inf inf inf inf inf]\n",
      "[nan nan]\n",
      "Accuracy: 0.5877192982456141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_9228\\1602263925.py:21: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.log(p / (1 - p))\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_9228\\1602263925.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(p / (1 - p))\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_9228\\1602263925.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1/(mu * (1 - mu))\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_9228\\1602263925.py:40: RuntimeWarning: invalid value encountered in multiply\n",
      "  z = eta + (y - mu) * logit_derivative(mu)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'df' is your DataFrame and you've already encoded the 'diagnosis' column as suggested\n",
    "df['diagnosis_dummy'] = (df['diagnosis'] == 'M').astype(int)\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "def logistic_regression_iwls(data, y_col, x_cols, max_iter=10):\n",
    "    data = data.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "    data['intercept'] = 1\n",
    "    x_cols = ['intercept'] + x_cols\n",
    "    \n",
    "    X = data[x_cols].values\n",
    "    y = data[y_col].values\n",
    "    \n",
    "    # Define the logit link function and its derivative\n",
    "    def logit(p):\n",
    "        return np.log(p / (1 - p))\n",
    "    \n",
    "    def logit_inv(eta):\n",
    "        return 1 / (1 + np.exp(-eta))\n",
    "\n",
    "    def logit_derivative(mu):\n",
    "        return 1/(mu * (1 - mu))\n",
    "    \n",
    "    # Initial estimates for mu and eta using y\n",
    "    mu = y.copy()\n",
    "    eta = logit(mu)\n",
    "    \n",
    "    # Initialize beta estimates\n",
    "    beta = np.zeros(X.shape[1])\n",
    "    print(\"mu\", mu)\n",
    "    print(\"LD\", logit_derivative(mu))\n",
    "    print(\"LD2\", logit_derivative(mu)**2)\n",
    "    for _ in range(max_iter):\n",
    "        # Update z and weights w\n",
    "        z = eta + (y - mu) * logit_derivative(mu)\n",
    "        w = logit_derivative(mu) ** 2 / (mu * (1 - mu))\n",
    "        \n",
    "        # Diagonal weight matrix\n",
    "        W = np.diag(w)\n",
    "        \n",
    "        # Update beta using weighted least squares\n",
    "        XTWX_inv = np.linalg.inv(X.T @ W @ X)\n",
    "        XTWZ = X.T @ W @ z\n",
    "        beta = XTWX_inv @ XTWZ\n",
    "        \n",
    "        # Update eta and mu\n",
    "        eta = X @ beta\n",
    "        mu = logit_inv(eta)\n",
    "    print(beta)\n",
    "    return beta\n",
    "\n",
    "# Train the model using IWLS\n",
    "x_cols = ['radius_mean']\n",
    "params = logistic_regression_iwls(df_train, 'diagnosis_dummy', x_cols)\n",
    "\n",
    "# Define the prediction function\n",
    "def predict(data, params):\n",
    "    data = data.copy()  # Make a copy to avoid modifying the original DataFrame\n",
    "    data['intercept'] = 1\n",
    "    X = data[['intercept', 'radius_mean']].values\n",
    "    linear_prediction = np.dot(X, params)\n",
    "    pred_prob = 1 / (1 + np.exp(-linear_prediction))\n",
    "    return pred_prob\n",
    "\n",
    "# Predict on test set\n",
    "df_test['pred_prob'] = predict(df_test, params)\n",
    "\n",
    "# Calculate accuracy\n",
    "df_test['predicted_diagnosis'] = (df_test['pred_prob'] > 0.5).astype(int)\n",
    "accuracy = (df_test['predicted_diagnosis'] == df_test['diagnosis_dummy']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512    1\n",
       "457    0\n",
       "439    0\n",
       "298    0\n",
       "37     0\n",
       "      ..\n",
       "213    1\n",
       "519    0\n",
       "432    1\n",
       "516    1\n",
       "500    0\n",
       "Name: diagnosis, Length: 114, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['diagnosis']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
